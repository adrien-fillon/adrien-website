
@book{harrer_doing_2022,
	address = {Boca Raton},
	edition = {First edition},
	title = {Doing meta-analysis with {R}: a hands-on guide},
	isbn = {978-1-00-310734-7},
	shorttitle = {Doing meta-analysis with {R}},
	abstract = {"This book serves as an accessible introduction into how meta-analyses can be conducted in R. Essential steps for meta-analysis are covered, including pooling of outcome measures, forest plots, heterogeneity diagnostics, subgroup analyses, meta-regression, methods to control for publication bias, risk of bias assessments and plotting tools. Advanced, but highly relevant topics such as network meta-analysis, multi-/three-level meta-analyses, Bayesian meta-analysis approaches, SEM meta-analysis are also covered. A companion R package, dmetar, is introduced in the beginning of the guide. It contains data sets and several helper functions for the meta and metafor package used in the guide"--},
	publisher = {CRC Press},
	author = {Harrer, Mathias},
	year = {2022},
	keywords = {Meta-analysis, R (Computer program language)},
}

@article{viechtbauer_conducting_2010,
	title = {Conducting meta-analyses in {R} with the metafor package},
	volume = {36},
	url = {https://doi.org/10.18637/jss.v036.i03},
	number = {3},
	journal = {Journal of Statistical Software},
	author = {Viechtbauer, Wolfgang},
	year = {2010},
	pages = {1--48},
}

@misc{jop_de_vrieze_meta-analyses_2018,
	title = {Meta-analyses were supposed to end scientific debates. {Often}, they only cause more controversy},
	url = {https://www.science.org/content/article/meta-analyses-were-supposed-end-scientific-debates-often-they-only-cause-more},
	abstract = {Compiling the evidence from dozens of studies doesn't always bring clarity},
	language = {en},
	urldate = {2023-03-09},
	journal = {Science},
	author = {{Jop de Vrieze}},
	year = {2018},
	file = {Snapshot:C\:\\Users\\adrie\\Zotero\\storage\\6W94NSZW\\meta-analyses-were-supposed-end-scientific-debates-often-they-only-cause-more.html:text/html},
}

@article{leclercq_methodological_2020,
	title = {Methodological quality of meta-analyses indexed in {PsycINFO}: leads for enhancements: a meta-epidemiological study},
	volume = {10},
	issn = {2044-6055},
	shorttitle = {Methodological quality of meta-analyses indexed in {PsycINFO}},
	doi = {10.1136/bmjopen-2019-036349},
	abstract = {OBJECTIVES: Meta-analyses (MAs) are often used because they are lauded to provide robust evidence that synthesises information from multiple studies. However, the validity of MA conclusions relies on the procedural rigour applied by the authors. Therefore, this meta-research study aims to characterise the methodological quality and meta-analytic practices of MAs indexed in PsycINFO.
DESIGN: A meta-epidemiological study.
PARTICIPANTS: We evaluated a random sample of 206 MAs indexed in the PsycINFO database in 2016.
PRIMARY AND SECONDARY OUTCOMES: Two authors independently extracted the methodological characteristics of all MAs and checked their quality according to the 16 items of the A MeaSurement Tool to Assess systematic Reviews (AMSTAR2) tool for MA critical appraisal. Moreover, we investigated the effect of mentioning Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) on the methodological quality of MAs.
RESULTS: According to AMSTAR2 criteria, 95\% of the 206 MAs were rated as critically low quality. Statistical methods were appropriate and publication bias was well evaluated in 87\% and 70\% of the MAs, respectively. However, much improvement is needed in data collection and analysis: only 11\% of MAs published a research protocol, 44\% had a comprehensive literature search strategy, 37\% assessed and 29\% interpreted the risk of bias in the individual included studies, and 11\% presented a list of excluded studies. Interestingly, the explicit mentioning of PRISMA suggested a positive influence on the methodological quality of MAs.
CONCLUSION: The methodological quality of MAs in our sample was critically low according to the AMSTAR2 criteria. Some efforts to tremendously improve the methodological quality of MAs could increase their robustness and reliability.},
	language = {eng},
	number = {8},
	journal = {BMJ open},
	author = {Leclercq, Victoria and Beaudart, Charlotte and Ajamieh, Sara and Tirelli, Ezio and Bruyère, Olivier},
	month = aug,
	year = {2020},
	pmid = {32747348},
	pmcid = {PMC7402002},
	keywords = {Bias, Epidemiologic Studies, epidemiology, Humans, public health, Publication Bias, Reproducibility of Results, Research Design, statistics \& research methods},
	pages = {e036349},
	file = {Texte intégral:C\:\\Users\\adrie\\Zotero\\storage\\GJBHVQ9R\\Leclercq et al. - 2020 - Methodological quality of meta-analyses indexed in.pdf:application/pdf},
}

@article{hohn_empirical_2020,
	title = {An {Empirical} {Review} of {Research} and {Reporting} {Practices} in {Psychological} {Meta}-{Analyses}},
	volume = {24},
	issn = {1089-2680},
	url = {https://doi.org/10.1177/1089268020918844},
	doi = {10.1177/1089268020918844},
	abstract = {As meta-analytic studies have come to occupy a sizable contingent of published work in the psychological sciences, clarity in the research and reporting practices of such work is crucial to the interpretability and reproducibility of research findings. The present study examines the state of research and reporting practices within a random sample of 384 published psychological meta-analyses across several important dimensions (e.g., search methods, exclusion criteria, statistical techniques). In addition, we surveyed the first authors of the meta-analyses in our sample to ask them directly about the research practices employed and reporting decisions made in their studies, including the assessments and procedures they conducted and the guidelines or materials they relied on. Upon cross-validating the first author responses with what was reported in their published meta-analyses, we identified numerous potential gaps in reporting and research practices. In addition to providing a survey of recent reporting practices, our findings suggest that (a) there are several research practices conducted by meta-analysts that are ultimately not reported; (b) some aspects of meta-analysis research appear to be conducted at disappointingly low rates; and (c) the adoption of the reporting standards, including the Meta-Analytic Reporting Standards (MARS), has been slow to nonexistent within psychological meta-analytic research.},
	language = {en},
	number = {3},
	urldate = {2023-03-09},
	journal = {Review of General Psychology},
	author = {Hohn, Richard E. and Slaney, Kathleen L. and Tafreshi, Donna},
	month = sep,
	year = {2020},
	note = {Publisher: SAGE Publications Inc},
	pages = {195--209},
	file = {SAGE PDF Full Text:C\:\\Users\\adrie\\Zotero\\storage\\2VZCQERX\\Hohn et al. - 2020 - An Empirical Review of Research and Reporting Prac.pdf:application/pdf},
}

@misc{stanley_practical_2019,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {Practical {Significance}, {Meta}-{Analysis} and the {Credibility} of {Economics}},
	url = {https://papers.ssrn.com/abstract=3427595},
	doi = {10.2139/ssrn.3427595},
	abstract = {Recently, there has been much discussion about replicability and credibility. By integrating the full research record, increasing statistical power, reducing bias and enhancing credibility, meta-analysis is widely regarded as 'best evidence'. Through Monte Carlo simulation, closely calibrated on the typical conditions found among 6,700 economics research papers, we find that large biases and high rates of false positives will often be found by conventional meta-analysis methods. Nonetheless, the routine application of meta-regression analysis and considerations of practical significance largely restore research credibility.},
	language = {en},
	urldate = {2023-03-09},
	author = {Stanley, T. D. and Doucouliagos, Hristos},
	month = jul,
	year = {2019},
	keywords = {credibility, meta-analysis, meta-regression, publication bias, simulations},
	file = {Full Text PDF:C\:\\Users\\adrie\\Zotero\\storage\\7AI8HSMV\\Stanley et Doucouliagos - 2019 - Practical Significance, Meta-Analysis and the Cred.pdf:application/pdf},
}

@article{hameed_assessment_2020,
	title = {An assessment of the quality of current clinical meta-analyses},
	volume = {20},
	issn = {1471-2288},
	url = {https://doi.org/10.1186/s12874-020-00999-9},
	doi = {10.1186/s12874-020-00999-9},
	abstract = {The objective of this study was to assess the overall quality of study-level meta-analyses in high-ranking journals using commonly employed guidelines and standards for systematic reviews and meta-analyses.},
	number = {1},
	urldate = {2023-03-09},
	journal = {BMC Medical Research Methodology},
	author = {Hameed, Irbaz and Demetres, Michelle and Tam, Derrick Y. and Rahouma, Mohamed and Khan, Faiza M. and Wright, Drew N. and Mages, Keith and DeRosa, Antonio P. and Baltich Nelson, Becky and Pain, Kevin and Delgado, Diana and Girardi, Leonard N. and Fremes, Stephen E. and Gaudino, Mario},
	month = may,
	year = {2020},
	keywords = {Clinical, Cochrane, Epidemiology, IOM, Meta-analysis, Methodology, PRESS, PRISMA, Quality},
	pages = {105},
	file = {Full Text PDF:C\:\\Users\\adrie\\Zotero\\storage\\8CL8G5FH\\Hameed et al. - 2020 - An assessment of the quality of current clinical m.pdf:application/pdf;Snapshot:C\:\\Users\\adrie\\Zotero\\storage\\B5L9QIUV\\s12874-020-00999-9.html:text/html},
}

@article{howick_most_2022,
	title = {Most healthcare interventions tested in {Cochrane} {Reviews} are not effective according to high quality evidence: a systematic review and meta-analysis},
	volume = {148},
	issn = {0895-4356},
	shorttitle = {Most healthcare interventions tested in {Cochrane} {Reviews} are not effective according to high quality evidence},
	url = {https://www.sciencedirect.com/science/article/pii/S0895435622001007},
	doi = {10.1016/j.jclinepi.2022.04.017},
	abstract = {Objective
To estimate the proportion of healthcare interventions tested within Cochrane Reviews that are effective according to high-quality evidence.
Methods
We selected a random sample of 2,428 (35\%) of all Cochrane Reviews published between 1 January 2008 and 5 March 2021. We extracted data about interventions within these reviews that were compared with placebo, or no treatment, and whose outcome quality was rated using the Grading of Recommendations Assessment, Development and Evaluation (GRADE) system. We calculated the proportion of interventions whose benefits were based on high-quality evidence (defined as having high quality GRADE rating for at least one primary outcome, statistically significant positive results, and being judged by review authors as effective. We also calculated the proportion of interventions that suggested harm.
Results
Of 1,567 eligible interventions, 87 (5.6\%) had high-quality evidence supporting their benefits. Harms were measured for 577 (36.8\%) interventions. There was statistically significant evidence for harm in 127 (8.1\%) of these. Our dependence on the reliability of Cochrane author assessments (including their GRADE assessments) was the main potential limitation of our study.
Conclusion
More than 9 in 10 healthcare interventions studied within recent Cochrane Reviews are not supported by high-quality evidence, and harms are under-reported.},
	language = {en},
	urldate = {2023-03-09},
	journal = {Journal of Clinical Epidemiology},
	author = {Howick, Jeremy and Koletsi, Despina and Ioannidis, John P. A. and Madigan, Claire and Pandis, Nikolaos and Loef, Martin and Walach, Harald and Sauer, Sebastian and Kleijnen, Jos and Seehra, Jadbinder and Johnson, Tess and Schmidt, Stefan},
	month = aug,
	year = {2022},
	keywords = {Epidemiology, Evidence, Harm, Quality, Safety, Systematic review},
	pages = {160--169},
	file = {ScienceDirect Snapshot:C\:\\Users\\adrie\\Zotero\\storage\\23H96VKV\\S0895435622001007.html:text/html},
}

@article{glass_primary_1976,
	title = {Primary, {Secondary}, and {Meta}-{Analysis} of {Research}},
	volume = {5},
	issn = {0013-189X},
	url = {https://doi.org/10.3102/0013189X005010003},
	doi = {10.3102/0013189X005010003},
	language = {en},
	number = {10},
	urldate = {2023-03-09},
	journal = {Educational Researcher},
	author = {Glass, GENE V},
	month = nov,
	year = {1976},
	note = {Publisher: American Educational Research Association},
	pages = {3--8},
}

@article{boseley_work_2019,
	chapter = {Science},
	title = {Work of renowned {UK} psychologist {Hans} {Eysenck} ruled ‘unsafe’},
	issn = {0261-3077},
	url = {https://www.theguardian.com/science/2019/oct/11/work-of-renowned-uk-psychologist-hans-eysenck-ruled-unsafe},
	abstract = {Eysenck’s ‘cancer-prone’ personality theory had come under criticism for decades},
	language = {en-GB},
	urldate = {2023-03-09},
	journal = {The Guardian},
	author = {Boseley, Sarah},
	month = oct,
	year = {2019},
	keywords = {Education, Higher education, King's College London, Psychology, Science, UK news},
	file = {Snapshot:C\:\\Users\\adrie\\Zotero\\storage\\GGUQTLIU\\work-of-renowned-uk-psychologist-hans-eysenck-ruled-unsafe.html:text/html},
}

@article{cuijpers_was_2019,
	title = {Was {Eysenck} right after all? {A} reassessment of the effects of psychotherapy for adult depression},
	volume = {28},
	issn = {2045-7960},
	shorttitle = {Was {Eysenck} right after all?},
	doi = {10.1017/S2045796018000057},
	abstract = {AIMS: In the 1950s, Eysenck suggested that psychotherapies may not be effective at all. Twenty-five years later, the first meta-analysis of randomised controlled trials showed that the effects of psychotherapies were considerable and that Eysenck was wrong. However, since that time methods have become available to assess biases in meta-analyses.
METHODS: We examined the influence of these biases on the effects of psychotherapies for adult depression, including risk of bias, publication bias and the exclusion of waiting list control groups.
RESULTS: The unadjusted effect size of psychotherapies compared with control groups was g = 0.70 (limited to Western countries: g = 0.63), which corresponds to a number-needed-to-treat of 4.18. Only 23\% of the studies could be considered as a low risk of bias. When adjusting for several sources of bias, the effect size across all types of therapies dropped to g = 0.31.
CONCLUSIONS: These results suggest that the effects of psychotherapy for depression are small, above the threshold that has been suggested as the minimal important difference in the treatment of depression, and Eysenck was probably wrong. However, this is still not certain because we could not adjust for all types of bias. Unadjusted meta-analyses of psychotherapies overestimate the effects considerably, and for several types of psychotherapy for adult depression, insufficient evidence is available that they are effective because too few low-risk studies were available, including problem-solving therapy, interpersonal psychotherapy and behavioural activation.},
	language = {eng},
	number = {1},
	journal = {Epidemiology and Psychiatric Sciences},
	author = {Cuijpers, P. and Karyotaki, E. and Reijnders, M. and Ebert, D. D.},
	month = feb,
	year = {2019},
	pmid = {29486804},
	pmcid = {PMC6999031},
	keywords = {Adult, Bias, Depression, Humans, outcome studies, psychotherapy, Psychotherapy, randomised controlled trials, Treatment Outcome},
	pages = {21--30},
	file = {Texte intégral:C\:\\Users\\adrie\\Zotero\\storage\\DJLPF7PS\\Cuijpers et al. - 2019 - Was Eysenck right after all A reassessment of the.pdf:application/pdf},
}

@book{borenstein_m_introduction_2021,
	title = {Introduction to {Meta}-{Analysis}, 2nd {Edition}},
	url = {https://www.wiley.com/en-us/Introduction+to+Meta+Analysis%2C+2nd+Edition-p-9781119558354},
	abstract = {A clear and thorough introduction to meta-analysis, the process of synthesizing data from a series of separate studies. The first edition of this text was widely acclaimed for the clarity of the presentation, and quickly established itself as the definitive text in this field. The fully updated second edition includes new and expanded content on avoiding common mistakes in meta-analysis, understanding heterogeneity in effects, publication bias, and more. Several brand-new chapters provide a systematic how to approach to performing and reporting a meta-analysis from start to finish. Written by four of the worlds foremost authorities on all aspects of meta-analysis, the new edition: Outlines the role of meta-analysis in the research process Shows how to compute effects sizes and treatment effects Explains the fixed-effect and random-effects models for synthesizing data Demonstrates how to assess and interpret variation in effect size across studies Explains how to avoid common mistakes in meta-analysis Discusses controversies in meta-analysis Includes access to a companion website containing videos, spreadsheets, data files, free software for prediction intervals, and step-by-step instructions for performing analyses using Comprehensive Meta-Analysis (CMA) Download videos, class materials, and worked examples at www.Introduction-to-Meta-Analysis.comThis book offers the reader a unified framework for thinking about meta-analysis, and then discusses all elements of the analysis within that framework. The authors address a series of common mistakes and explain how to avoid them. As the editor-in-chief of the American Psychologist and former editor of Psychological Bulletin, I can say without hesitation that the quality of manuscript submissions reporting meta-analyses would be vastly better if researchers read this book. Harris Cooper, Hugo L. Blomquist Distinguished Professor Emeritus of Psychology and Neuroscience, Editor-in-chief of the American Psychologist, former editor of Psychological Bulletin A superb combination of lucid prose and informative graphics, the authors provide a refreshing departure from cookbook approaches with their clear explanations of the what and why of meta-analysis. The book is ideal as a course textbook or for self-study. My students raved about the clarity of the explanations and examples. David Rindskopf, Distinguished Professor of Educational Psychology, City University of New York, Graduate School and University Center, Editor of the Journal of Educational and Behavioral Statistics. The approach taken by Introduction to Meta-analysis is intended to be primarily conceptual, and it is amazingly successful at achieving that goal. The reader can comfortably skip the formulas and still understand their application and underlying motivation. For the more statistically sophisticated reader, the relevant formulas and worked examples provide a superb practical guide to performing a meta-analysis. The book provides an eclectic mix of examples from education, social science, biomedical studies, and even ecology. For anyone considering leading a course in meta-analysis, or pursuing self-directed study, Introduction to Meta-analysis would be a clear first choice. Jesse A. Berlin, ScD This book offers the reader a unified framework for thinking about meta-analysis, and then discusses all elements of the analysis within that framework. The authors address a series of common mistakes and explain how to avoid them. As the editor-in-chief of the American Psychologist and former editor of Psychological Bulletin, I can say without hesitation that the quality of manuscript submissions reporting meta-analyses would be vastly better if researchers read this book. Harris Cooper, Hugo L. Blomquist Distinguished Professor Emeritus of Psychology and Neuroscience, Editor-in-chief of the American Psychologist, former editor of Psychological Bulletin A superb combination of lucid prose and informative graphics, the authors provide a refreshing departure from cookbook approaches with their clear explanations of the what and why of meta-analysis. The book is ideal as a course textbook or for self-study. My students raved about the clarity of the explanations and examples. David Rindskopf, Distinguished Professor of Educational Psychology, City University of New York, Graduate School and University Center, Editor of the Journal of Educational and Behavioral Statistics. The approach taken by Introduction to Meta-analysis is intended to be primarily conceptual, and it is amazingly successful at achieving that goal. The reader can comfortably skip the formulas and still understand their application and underlying motivation. For the more statistically sophisticated reader, the relevant formulas and worked examples provide a superb practical guide to performing a meta-analysis. The book provides an eclectic mix of examples from education, social science, biomedical studies, and even ecology. For anyone considering leading a course in meta-analysis, or pursuing self-directed study, Introduction to Meta-analysis would be a clear first choice. Jesse A. Berl},
	language = {en-us},
	urldate = {2023-03-09},
	author = {Borenstein, M. and Hedges, L. and Higgins, V. and and Rothstein, J. P. T.},
	year = {2021},
}

@book{schmidt_methods_2015,
	address = {1 Oliver's Yard, 55 City Road London EC1Y 1SP},
	title = {Methods of {Meta}-{Analysis}: {Correcting} {Error} and {Bias} in {Research} {Findings}},
	isbn = {978-1-4522-8689-1 978-1-4833-9810-5},
	shorttitle = {Methods of {Meta}-{Analysis}},
	url = {https://methods.sagepub.com/book/methods-of-meta-analysis-3e},
	urldate = {2023-03-09},
	publisher = {SAGE Publications, Ltd},
	author = {Schmidt, Frank L. and Hunter, John E.},
	year = {2015},
	doi = {10.4135/9781483398105},
}
